{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8fb3a4f",
   "metadata": {},
   "source": [
    "# PFT Dataset Preprocessing\n",
    "This script is doing the necessary preprocessing of the Plant-Functional-Types dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba90389",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8f602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28da3c",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "This dataset is about Plant-Functional-Types (PFT). This dataset can only be manually dowloaded from [CEDA Archive](https://catalogue.ceda.ac.uk/uuid/26a0f46c95ee4c29b5c650b129aab788) and contains every single year in a seperate file, so after it was regridded it has to be aggregated into a single file. Click on download and select the file called *ESACCI-LC-L4-PFT-Map-300m-P1Y-1992-2020-v2.0.8.zip* (44.5GB as a zip) and place it under [data/original_pft_data/](data/era5_climate_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799ab452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the dataset\n",
    "ZipFile(\"data/original_pft_data/ESACCI-LC-L4-PFT-Map-300m-P1Y-1992-2020-v2.0.8.zip\").extractall(\"data/original_pft_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6ef8f4",
   "metadata": {},
   "source": [
    "### Regridding\n",
    "Regrid the pft data to fit the grid size of 0.1° by 0.1° of the ERA5 climate data. The regridding is weighted by area in m² of a grid cell. The area of a cell is latitude dependent and can be calculated using the earths radius. Since it is latitude dependent we don't need to create a whole matrix lat x lon because it will be the same across a specific latitude, but we can just have a lat dependent vector.\n",
    "\n",
    "WGS84 means the World Geodetic System 1984 which is a widely used reference system for coordinate based calculations etc.\n",
    "\n",
    "**Sources:**\n",
    "1. [Luke Gloege on Medium.com](https://medium.com/data-science/the-correct-way-to-average-the-globe-92ceecd172b7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55f4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def earth_radius(lat):\n",
    "    '''\n",
    "    Calculate the radius of Earth based on latitude assuming oblate spheroid defined by WGS84\n",
    "    '''\n",
    "    a = 6378137\n",
    "    b = 6356752.3142\n",
    "    e2 = 1 - (b**2/a**2)\n",
    "\n",
    "    lat_rad = np.deg2rad(lat)\n",
    "    lat_gc = np.arctan((1 - e2) * np.tan(lat_rad))\n",
    "\n",
    "    radius = (a * (1 - e2)**0.5) / (1 - (e2 * np.cos(lat_gc)**2))**0.5\n",
    "    \n",
    "    return radius\n",
    "\n",
    "def area_weights(lat_deg: xr.DataArray, lon_deg: xr.DataArray):\n",
    "    \"\"\"\n",
    "    Return 1D array of cell areas (m^2 per cell, *per longitude*) for each latitude row\n",
    "    on a regular lat/lon grid with uniform spacing.\n",
    "\n",
    "    lat_deg, lon_deg: 1D arrays of grid *centers* in degrees (uniform spacing assumed)\n",
    "    \"\"\"\n",
    "\n",
    "    R = earth_radius(lat_deg)\n",
    "\n",
    "    dlat_deg = abs(np.diff(lat_deg).mean())\n",
    "    dlon_deg = abs(np.diff(lon_deg).mean())\n",
    "    \n",
    "    lat_rad    = np.deg2rad(lat_deg)\n",
    "    dlat_rad   = np.deg2rad(dlat_deg)\n",
    "    dlon_rad   = np.deg2rad(dlon_deg)\n",
    "\n",
    "    lat_up   = np.clip(lat_rad + dlat_rad/2, -np.pi/2,  np.pi/2)\n",
    "    lat_down = np.clip(lat_rad - dlat_rad/2, -np.pi/2,  np.pi/2)\n",
    "\n",
    "    w_lat = np.square(R) * (np.sin(lat_up) - np.sin(lat_down)) * dlon_rad \n",
    "\n",
    "    w_lat_values = w_lat.values if isinstance(w_lat, xr.DataArray) else w_lat\n",
    "    lat_values = lat_deg.values if isinstance(lat_deg, xr.DataArray) else lat_deg\n",
    "    \n",
    "    area_weights = xr.DataArray(\n",
    "        w_lat_values,\n",
    "        dims=[\"lat\"],\n",
    "        coords={\"lat\": lat_values},\n",
    "        attrs={\n",
    "            \"long_name\": \"area_weight_per_cell\",\n",
    "            \"description\": \"Area weight per grid cell (m^2 per longitude cell)\",\n",
    "            \"units\": \"m^2\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return area_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e6fe6e",
   "metadata": {},
   "source": [
    "To regrid a single variable of the pft data the cells are aggregated by a specific factor to match the target resolution of 0.1 in degrees. In our case that factor is exactly 36, which makes the aggregation no problem since we can aggregate exactly 36 by 36 cells and the resolution will fit the target resolution perfectly. To manage memory usage, each variable has to be processed individually and temporarily saved to a file to be aggregated back into one dataset at the end of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1cc1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conservative_regrid_single_var(\n",
    "    filepath: str,\n",
    "    var_name: str, \n",
    "    weights_fine: xr.DataArray, \n",
    "    target_resolution: float\n",
    ") -> xr.DataArray:\n",
    "    \n",
    "    with xr.open_dataset(filepath, chunks=\"auto\") as ds:\n",
    "        data_var = ds[var_name]\n",
    "    \n",
    "    dlat_fine = np.abs(np.diff(data_var.lat).mean())\n",
    "    lat_factor = int(np.round(target_resolution / dlat_fine))\n",
    "    lon_factor = lat_factor\n",
    "    \n",
    "    data_var_weighted = data_var * weights_fine\n",
    "    \n",
    "    numerator = data_var_weighted.coarsen(lat=lat_factor, lon=lon_factor).sum()\n",
    "    denominator = weights_fine.coarsen(lat=lat_factor).sum() * lon_factor\n",
    "    \n",
    "    result = ((numerator / denominator)  / 100).astype('float32').compute()\n",
    "    \n",
    "    result.attrs = data_var.attrs\n",
    "\n",
    "    del data_var, data_var_weighted, numerator, denominator\n",
    "    gc.collect()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def conservative_regrid_multiple_var(\n",
    "    filepath: str,\n",
    "    var_names: list[str], \n",
    "    target_resolution: float,\n",
    "    target_filepath: str\n",
    ") -> xr.Dataset:\n",
    "    \n",
    "    temp_path = Path(\"data/temp_regrid\")\n",
    "    temp_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    ds = xr.open_dataset(filepath, chunks=\"auto\")\n",
    "    weights = area_weights(ds.lat, ds.lon)\n",
    "    del ds\n",
    "    gc.collect()\n",
    "\n",
    "    temp_files: list[Path] = []\n",
    "    for var in var_names:\n",
    "        print(f'Processing variable {var}')\n",
    "\n",
    "        var_regridded = conservative_regrid_single_var(filepath, var, weights, target_resolution)\n",
    "        temp_ds = var_regridded.to_dataset(name=var)\n",
    "\n",
    "        temp_file = temp_path / f\"{var}_temp.nc\"\n",
    "        temp_ds.to_netcdf(temp_file)\n",
    "        temp_files.append(temp_file)\n",
    "        del var_regridded, temp_ds\n",
    "        gc.collect()\n",
    "\n",
    "    data_vars = {}\n",
    "    for temp_file in temp_files:\n",
    "        var_name = temp_file.stem.replace(\"_temp\", \"\")\n",
    "        with xr.open_dataset(temp_file) as ds_temp:\n",
    "            data_vars[var_name] = ds_temp[var_name].load()\n",
    "        gc.collect()\n",
    "    \n",
    "    ds_regridded = xr.Dataset(data_vars)\n",
    "    ds_regridded.to_netcdf(target_filepath)\n",
    "\n",
    "    for temp_file in temp_files:\n",
    "        temp_file.unlink()\n",
    "        \n",
    "    return ds_regridded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dde31f",
   "metadata": {},
   "source": [
    "Now run the regridding only for these specific variables (no need for the aggregated variables LAND and WATER). All files (each file represents a single year) have to be loaded one by one. The regridded datasets will be saved under [data/regridded_pft_data](data/regridded_pft_data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae4c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PFT_VARS = [\n",
    "    \"BARE\",\"BUILT\",\n",
    "    \"GRASS-MAN\",\"GRASS-NAT\",\n",
    "    \"SHRUBS-BD\",\"SHRUBS-BE\",\"SHRUBS-ND\",\"SHRUBS-NE\",\n",
    "    \"TREES-BD\",\"TREES-BE\",\"TREES-ND\",\"TREES-NE\",\n",
    "    \"WATER_OCEAN\",\"WATER_INLAND\",\"SNOWICE\"\n",
    "]\n",
    "\n",
    "years = range(1992, 2021)\n",
    "\n",
    "output_dir = Path(\"data/regridded_pft_data\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    filepath = f\"data/original_pft_data/ESACCI-LC-L4-PFT-Map-300m-P1Y-{year}-v2.0.8.nc\"\n",
    "    target_filepath = output_dir / f\"pft_{year}_0.1deg.nc\"\n",
    "    print(f\"Processing year {year}\")\n",
    "    try:\n",
    "        ds_regridded = conservative_regrid_multiple_var(filepath, PFT_VARS, target_resolution=0.1, target_filepath=target_filepath)\n",
    "\n",
    "        del ds_regridded\n",
    "        gc.collect()\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing year {year}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00976483",
   "metadata": {},
   "source": [
    "### Aggregation and Slicing\n",
    "For convenience all seperate files (single years) are aggregated into a single dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccc0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "regridded_dir = Path(\"data/regridded_pft_data\")\n",
    "regridded_files = sorted(regridded_dir.glob(\"pft_*_0.1deg.nc\"))\n",
    "\n",
    "print(f\"Found {len(regridded_files)} regridded PFT files\")\n",
    "\n",
    "datasets = []\n",
    "years = []\n",
    "\n",
    "for filepath in regridded_files:\n",
    "    year = int(filepath.stem.split('_')[1])\n",
    "    years.append(year)\n",
    "    \n",
    "    ds = xr.open_dataset(filepath)\n",
    "    \n",
    "    # Remove time dimension\n",
    "    if 'time' in ds.dims:\n",
    "        ds = ds.isel(time=0).drop_vars('time')\n",
    "    \n",
    "    # Add year as a coordinate to match ERA5 data\n",
    "    ds = ds.assign_coords(year=year)\n",
    "    datasets.append(ds)\n",
    "    \n",
    "    print(f\"Loaded year {year}\")\n",
    "\n",
    "# Concatenate along year dimension\n",
    "ds_combined = xr.concat(datasets, dim='year')\n",
    "\n",
    "# Sort by year to ensure correct order\n",
    "ds_combined = ds_combined.sortby('year')\n",
    "\n",
    "# Add metadata\n",
    "ds_combined.attrs.update({\n",
    "    'title': 'Combined PFT data 1992-2020 at 0.1° resolution',\n",
    "    'description': 'Plant Functional Type fractions regridded from 300m to 0.1° resolution using conservative regridding',\n",
    "    'source': 'ESA CCI Land Cover',\n",
    "    'resolution': '0.1 degrees',\n",
    "    'time_coverage': '1992-2020'\n",
    "})\n",
    "\n",
    "ds_combined.to_netcdf(\"data/regridded_pft_data/pft_combined_1992-2020.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17563111",
   "metadata": {},
   "source": [
    "Rename spatial dimensions to match naming in the ERA5 climate dataset. Then also align the coordinates because of shifts because of computational numerical errors and centering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59bb828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_combined = xr.open_dataset(\"data/regridded_pft_data/pft_combined_1992-2020_0.1deg.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe3ae8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename latitude and longitude dimensions to match climate dataset\n",
    "ds_pft = ds_combined.rename({'lat':'latitude', 'lon':'longitude'})\n",
    "\n",
    "# Load climate dataset to align latitude/longitude coordinates\n",
    "ds_era5 = xr.open_dataset(\"data/era5_climate_data/era5-land-monthly-means-1992-2020.nc\")\n",
    "\n",
    "def to_lon180(ds, lon_name='longitude'):\n",
    "    lon = ds[lon_name]\n",
    "    lon180 = ((lon + 180) % 360) - 180\n",
    "    return ds.assign_coords({lon_name: lon180}).sortby(lon_name)\n",
    "\n",
    "ds_era5 = to_lon180(ds_era5)\n",
    "\n",
    "# Align grids\n",
    "ds_pft = ds_pft.reindex_like(\n",
    "    ds_era5,  \n",
    "    method='nearest',\n",
    "    tolerance=0.051  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e437e028",
   "metadata": {},
   "source": [
    "Slice dataset to region of Europe and North Africe like described in *era5_data_preprocessing.ipynb*. And start by year 1993 to match ERA5 data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaf9d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_pft_sliced = ds_pft.sel(longitude=slice(-11, 40), latitude=slice(72, 30))\n",
    "ds_pft_sliced = ds_pft_sliced.sel(year=slice(1993, 2020))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c0936c",
   "metadata": {},
   "source": [
    "Finally save the dataset to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92c0d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"data/regridded_pft_data/pft-yearly-sliced.nc\"\n",
    "ds_pft_sliced.to_netcdf(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "climatepft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
